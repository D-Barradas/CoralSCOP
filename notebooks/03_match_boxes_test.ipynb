{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load manipilation_library\n",
    "import sys\n",
    "sys.path.append('./manipulation_library.py') # add the path of manipulation_library.py\n",
    "from manipulation_library import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_center(bbox):\n",
    "    \"\"\"\n",
    "    Calculate the center of a bounding box.\n",
    "    bbox: [x_min, y_min, x_max, y_max]\n",
    "    \"\"\"\n",
    "    x_center = (bbox[0] + bbox[2]) / 2\n",
    "    y_center = (bbox[1] + bbox[3]) / 2\n",
    "    return np.array([x_center, y_center])\n",
    "\n",
    "def euclidean_distance(point1, point2):\n",
    "    \"\"\"\n",
    "    Calculate the Euclidean distance between two points.\n",
    "    \"\"\"\n",
    "    return np.linalg.norm(point1 - point2)\n",
    "\n",
    "def find_close_bounding_boxes(ocr_bboxes, seg_bboxes, threshold):\n",
    "    \"\"\"\n",
    "    Find OCR bounding boxes that are close to segmentation bounding boxes.\n",
    "    ocr_bboxes: List of OCR bounding boxes\n",
    "    seg_bboxes: List of segmentation bounding boxes\n",
    "    threshold: Distance threshold to consider bounding boxes as close\n",
    "    \"\"\"\n",
    "    close_bboxes = []\n",
    "    close_bboxes_indices = []\n",
    "    for idx_ocr, ocr_bbox in enumerate(ocr_bboxes):\n",
    "        ocr_center = get_center(ocr_bbox)\n",
    "        for idx, seg_bbox in enumerate(seg_bboxes):\n",
    "            seg_center = get_center(seg_bbox)\n",
    "            distance = euclidean_distance(ocr_center, seg_center)\n",
    "            if distance <= threshold and ocr_bbox[1] < seg_bbox[1]:\n",
    "                close_bboxes.append((ocr_bbox, seg_bbox))\n",
    "                close_bboxes_indices.append((idx, idx_ocr))\n",
    "    return close_bboxes, close_bboxes_indices\n",
    "\n",
    "def find_unpaired_seg_bboxes(seg_bboxes, close_bboxes_indices):\n",
    "    \n",
    "    \"\"\"\n",
    "    Find segmentation bounding boxes that do not have a paired OCR bounding box.\n",
    "    seg_bboxes: List of segmentation bounding boxes\n",
    "    close_bboxes_indices: List of indices of close bounding boxes\n",
    "    \"\"\"\n",
    "    paired_seg_indices = {pair[0] for pair in close_bboxes_indices}\n",
    "    unpaired_seg_indices = [idx for idx in range(len(seg_bboxes)) if idx not in paired_seg_indices]\n",
    "    return unpaired_seg_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Example usage\n",
    "# ocr_bboxes = [[10, 20, 50, 60], [100, 120, 150, 160]]  # Replace with actual OCR bounding boxes\n",
    "# seg_bboxes = [[12, 22, 52, 62], [200, 220, 250, 260]]  # Replace with actual segmentation bounding boxes\n",
    "# threshold = 10  # Define your threshold distance\n",
    "\n",
    "# close_bboxes = find_close_bounding_boxes(ocr_bboxes, seg_bboxes, threshold)\n",
    "# print(close_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = '/home/barradd/Documents/GitHub/CoralSCOP/data/raw/Exp8-CBS-080724'\n",
    "path_to_coral = f'{main_path}/TL8_2799.jpg'\n",
    "image = get_image(path_to_coral)\n",
    "image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = easyocr.Reader(['en'],gpu=True) # this needs to run only once to load the model into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = reader.readtext(image)\n",
    "ocr_bboxes, text_list = OcrAnalysis.get_bounding_boxes(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_generator = load_sam_model(model_type=\"vit_b\")\n",
    "masks = mask_generator.generate(image=image)\n",
    "# list_of_images , titles , image_dataframe = process_images_and_sort_by_coordinates(image = image, masks= masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_bboxes = [    ]\n",
    "for i in range(len(masks)):\n",
    "    x, y, width, height = masks[i]['bbox']\n",
    "    seg_bboxes.append ( np.array([x, y, x+width, y+height]) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_bboxes[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_bboxes[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 50  # Define your threshold distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_bboxes = find_close_bounding_boxes(ocr_bboxes, seg_bboxes, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(close_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(close_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100,150,5):\n",
    "    threshold = i\n",
    "    close_bboxes ,close_bboxes_indices = find_close_bounding_boxes(ocr_bboxes, seg_bboxes, threshold)\n",
    "    print(f'{threshold} : {len(close_bboxes)} , {close_bboxes_indices}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Set the threshold\n",
    "# this seems to be the best threshold for these images\n",
    "threshold = 125\n",
    "\n",
    "# Find close bounding boxes with the new threshold\n",
    "close_bboxes, close_bboxes_indices = find_close_bounding_boxes(ocr_bboxes, seg_bboxes, threshold)\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots(1, figsize=(12, 12))\n",
    "\n",
    "# Display the image\n",
    "ax.imshow(image)\n",
    "\n",
    "# Define colors for bounding boxes\n",
    "colors = plt.get_cmap('tab20', len(close_bboxes))\n",
    "\n",
    "# Plot OCR and segmentation bounding boxes\n",
    "for idx, (ocr_bbox, seg_bbox) in enumerate(close_bboxes):\n",
    "    color = colors(idx)\n",
    "    \n",
    "    # OCR bounding box\n",
    "    rect_ocr = patches.Rectangle((ocr_bbox[0], ocr_bbox[1]), ocr_bbox[2] - ocr_bbox[0], ocr_bbox[3] - ocr_bbox[1], linewidth=2, edgecolor=color, facecolor='none', label=f'OCR {idx}')\n",
    "    ax.add_patch(rect_ocr)\n",
    "    \n",
    "    # Segmentation bounding box\n",
    "    rect_seg = patches.Rectangle((seg_bbox[0], seg_bbox[1]), seg_bbox[2] - seg_bbox[0], seg_bbox[3] - seg_bbox[1], linewidth=2, edgecolor=color, facecolor='none', linestyle='dashed', label=f'Seg {idx}')\n",
    "    ax.add_patch(rect_seg)\n",
    "\n",
    "# Add legend\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "# ax.legend(by_label.values(), by_label.keys())\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "# save the plot\n",
    "fig.savefig('../data/final/bounding_boxes.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort masks in the same order as close_bboxes \n",
    "sorted_masks = []\n",
    "for idx, _ in close_bboxes_indices:\n",
    "    sorted_masks.append(masks[idx])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def background_to_black ( image, index , masks  ):\n",
    "    # Apply the mask to the image\n",
    "    masked_img = image.copy()\n",
    "    masked_pixels = masked_img[masks[index]['segmentation']==True]\n",
    "    masked_img[masks[index]['segmentation']==False] = (0, 0, 0)  # Set masked pixels to black\n",
    "    return masked_img ,masked_pixels\n",
    "\n",
    "\n",
    "def use_sorted_mask(image, masks):\n",
    "    cropped_image_list = []\n",
    "    for i in range(len(masks)):\n",
    "        x, y, width, height = masks[i]['bbox']\n",
    "        image_b, masked_pixels = background_to_black(image=image, index=i , masks=masks)\n",
    "        cropped_image = image_b[int(y):int(y+height), int(x):int(x+width)]\n",
    "        cropped_image_list.append(cropped_image)\n",
    "\n",
    "    return cropped_image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images_and_use_sorted_mask(image, masks):\n",
    "    cropped_image_list  = use_sorted_mask( image=image , masks=masks )\n",
    "    return cropped_image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_image_list = process_images_and_use_sorted_mask(image, sorted_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets output the images to ../data/interrim/Exp8-CBS-080724 , \n",
    "# the name of the image will be the same as the original image with the index of the sorted_masks appended to it\n",
    "# the name also must include the number of the ocr bounding box that is close to the segmentation bounding box\n",
    "# the image will be saved as a jpg file\n",
    "for idx, image_segment in enumerate( cropped_image_list) :\n",
    "    index_segmetation , index_ocr = close_bboxes_indices[idx]\n",
    "    pred_text = text_list[index_ocr]\n",
    "    image_segment = cv2.cvtColor(image_segment, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(f'../data/interim/image_index_{index_ocr}_{index_segmetation}_tag_{pred_text}.jpg',image_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the segmentation bounding boxes that do not have a paired OCR bounding box\n",
    "unpaired_seg_indices = find_unpaired_seg_bboxes(seg_bboxes, close_bboxes_indices)\n",
    "# get the images for the unpaired segmentation bounding boxes\n",
    "unpaired_images = []\n",
    "for idx in unpaired_seg_indices:\n",
    "    x, y, width, height = seg_bboxes[idx]\n",
    "    image_b, masked_pixels = background_to_black(image=image, index=idx , masks=masks)\n",
    "    cropped_image = image_b[int(y):int(y+height), int(x):int(x+width)]\n",
    "    unpaired_images.append(cropped_image)\n",
    "\n",
    "# now lets output the images to ../data/interrim/ , lets add tag \"unpaired\" to the name of the image\n",
    "# the image will be saved as a jpg file\n",
    "for idx, image_segment in enumerate( unpaired_images) :\n",
    "    image_segment = cv2.cvtColor(image_segment, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(f'../data/interim/image_unpaired_{idx}.jpg',image_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
