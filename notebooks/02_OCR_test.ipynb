{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from glob import glob \n",
    "# from sklearn.cluster import KMeans\n",
    "from collections import Counter\n",
    "# from skimage.color import rgb2lab, deltaE_cie76\n",
    "import pandas as pd\n",
    "import easyocr , os , ssl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the segment_anything library that is one folder up \n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (1200, 800))\n",
    "\n",
    "    # image = preprocess_histograms( image=image)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_box(box, ax, color='green'):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor=color, facecolor=(0,0,0,0), lw=2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_cuda_available():\n",
    "    \"\"\"Checks if CUDA is available and can be used by PyTorch.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if CUDA is available, False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    return torch.cuda.is_available()\n",
    "\n",
    "def load_sam_model(model_type):\n",
    "    ## Load the model for segmentation ( the SAM deep learning algorithm )\n",
    "    # from segment_anything import sam_model_registry, SamAutomaticMaskGenerator\n",
    "    # path_to_models = \"/\".join(os.getcwd().split(\"/\")[:-1])\n",
    "\n",
    "    # model_type = \"vit_l\"\n",
    "\n",
    "    sam_checkpoint = {'vit_h':'../models/sam_vit_h_4b8939.pth', \n",
    "                  'vit_l':'../models/sam_vit_l_0b3195.pth',\n",
    "                #   'vit_b':'../models/sam_vit_b_01ec64.pth',\n",
    "                  'vit_b': '../checkpoints/vit_b_coralscop.pth'}\n",
    "\n",
    "    if is_cuda_available():\n",
    "        # The following line is for using my second GPU, free\n",
    "        # device = torch.device(\"cuda:1\")\n",
    "        print(\"CUDA is available!\")\n",
    "        device = torch.device(\"cuda:1\")\n",
    "    else:\n",
    "        print(\"CUDA is not available. Using CPU.\")\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "    sam = sam_model_registry[model_type](checkpoint=sam_checkpoint[model_type])\n",
    "    sam.to(device=device)\n",
    "# python test.py --model_type vit_b --checkpoint_path ./checkpoints/vit_b_coralscop.pth --iou_threshold 0.72 --sta_threshold 0.62 --test_img_path ./demo_imgs/ --output_path ./demo_imgs_output --gpu 0 --point_number 32\n",
    "    points_per_side = 32\n",
    "    pred_iou_thresh = 0.72\n",
    "    stability_score_thresh = 0.62\n",
    "    # mask_generator = SamAutomaticMaskGenerator(sam)\n",
    "    mask_generator = SamAutomaticMaskGenerator(\n",
    "        model=sam,\n",
    "        points_per_side=points_per_side,\n",
    "        pred_iou_thresh=pred_iou_thresh,\n",
    "        stability_score_thresh=stability_score_thresh,\n",
    "        crop_n_layers=1,\n",
    "        crop_n_points_downscale_factor=2,\n",
    "        min_mask_region_area=100,  # Requires open-cv to run post-processing\n",
    "    )\n",
    "    return mask_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OcrAnalysis:\n",
    "    \"\"\"Performs analysis on OCR (Optical Character Recognition) results.\n",
    "\n",
    "    Attributes:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initializes the OcrAnalysis class.\"\"\"\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def get_bounding_boxes(results):\n",
    "        \"\"\"Extracts bounding boxes and text from OCR results.\n",
    "\n",
    "        Args:\n",
    "            results: An iterable of tuples containing individual OCR results,\n",
    "                each tuple having the format (bbox, text, prob) where:\n",
    "                    - bbox: A list/tuple of coordinates representing the bounding box.\n",
    "                    - text: The recognized text within the bounding box.\n",
    "                    - prob: The confidence probability score (optional).\n",
    "\n",
    "        Returns:\n",
    "            A tuple of two lists:\n",
    "                - The first list contains bounding boxes as NumPy arrays.\n",
    "                - The second list contains the corresponding recognized text.\n",
    "        \"\"\"\n",
    "\n",
    "        bboxes, text_list = [], []\n",
    "        for bbox, text, _ in results:\n",
    "            # Extract and convert coordinates to integers\n",
    "            top_left, top_right, bottom_right, bottom_left = bbox\n",
    "            box = np.array([int(coord) for coord in [top_left[0], top_left[1], bottom_right[0], bottom_right[1]]])\n",
    "            bboxes.append(box)\n",
    "            text_list.append(text)\n",
    "        return bboxes, text_list\n",
    "\n",
    "    @staticmethod\n",
    "    def get_pixels_above_bbox(bbox, image):\n",
    "        \"\"\"Extracts the region above the given bounding box from an image.\n",
    "\n",
    "        Args:\n",
    "            bbox: A list/tuple representing the bounding box as [x, y, width, height].\n",
    "            image: The NumPy array representing the image.\n",
    "\n",
    "        Returns:\n",
    "            A NumPy array containing the cropped image region.\n",
    "        \"\"\"\n",
    "\n",
    "        x, y, w, h = bbox\n",
    "        box_height = 50\n",
    "        # Clamp coordinates to image boundaries\n",
    "        top_left_y = max(0, y - box_height)\n",
    "        top_left_x = x\n",
    "        bottom_right_y = y\n",
    "        bottom_right_x = min(w, image.shape[1])  # Clamp right edge to image width\n",
    "\n",
    "        cropped_image = image[top_left_y:bottom_right_y, top_left_x:bottom_right_x]\n",
    "        return cropped_image\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_custom_colorchart(custom_rgb_chart):\n",
    "        # Calculate the number of squares based on the dictionary length\n",
    "        num_squares = len(custom_rgb_chart)\n",
    "\n",
    "        # Define figure size and square width\n",
    "        fig, ax = plt.subplots(figsize=(10, num_squares * 0.15))\n",
    "        square_width = 0.8\n",
    "\n",
    "        # Iterate over the dictionary and plot squares\n",
    "        for i, (color_name, color_value) in enumerate(custom_rgb_chart.items()):\n",
    "\n",
    "\n",
    "            # Normalize color values for plotting\n",
    "            normalized_color = [c / 255 for c in color_value]\n",
    "            # print ( normalized_color[0], len( normalized_color[0]))\n",
    "\n",
    "\n",
    "            # Calculate x position based on square width and offset\n",
    "            x_pos = i * square_width\n",
    "\n",
    "            # Create and plot the square\n",
    "            square = plt.Rectangle(\n",
    "                xy=(x_pos, 0), width=square_width, height=1, color=normalized_color\n",
    "            )\n",
    "            ax.add_patch(square)\n",
    "\n",
    "            # Add color name label above the square\n",
    "            ax.text(\n",
    "                x_pos + square_width / 2,\n",
    "                1.15,\n",
    "                color_name,\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                fontsize=10,\n",
    "                weight=\"bold\",rotation=90\n",
    "            )\n",
    "\n",
    "        # Set axis limits and labels\n",
    "        ax.set_xlim([0, num_squares * square_width])\n",
    "        ax.set_ylim([-0.2, 1.3])\n",
    "        ax.set_xlabel(\"Color Name\")\n",
    "        ax.set_ylabel(\"Color Chart\")\n",
    "\n",
    "        # Remove unnecessary ticks and grid\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.grid(False)\n",
    "\n",
    "        # Show the plot\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize images\n",
    "def show_images_grid(images, titles=None, figsize=(20, 20)):\n",
    "    \"\"\"Displays a grid of images with optional titles.\"\"\"\n",
    "\n",
    "    num_images = len(images)\n",
    "    rows = int(num_images / 2)\n",
    "    cols = 2\n",
    "\n",
    "    # Create a figure and subplots\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=figsize)\n",
    "\n",
    "    # Flatten the subplots array for easier iteration\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, ax in enumerate(axes):\n",
    "        if i < num_images:\n",
    "            img = images[i]\n",
    "            ax.imshow(img)\n",
    "            # ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))  # Convert to RGB for Matplotlib\n",
    "            ax.axis('off')  # Hide axes\n",
    "\n",
    "            if titles:\n",
    "                ax.set_title(titles[i])\n",
    "        else:\n",
    "            ax.axis('off')  # Hide unused subplots\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = '/home/barradd/Documents/GitHub/CoralSCOP/data/raw/Exp8-CBS-080724'\n",
    "path_to_coral = f'{main_path}/TL8_2799.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = get_image(path_to_coral)\n",
    "image = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = easyocr.Reader(['en'],gpu=True) # this needs to run only once to load the model into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = reader.readtext(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes , pred_text = [], []\n",
    "for (bbox, text, prob) in result:\n",
    "    (top_l, top_r, bottom_r, bottom_l) = bbox\n",
    "    tl = ( int(top_l[0]) ,int(top_l[1])   )\n",
    "    tr = ( int(top_r[0]) ,int(top_r[1])   )\n",
    "    bl = ( int(bottom_l[0]) ,int(bottom_l[1])   )\n",
    "    br = ( int(bottom_r[0]) ,int(bottom_r[1])   )\n",
    "    box = np.array( [int(top_l[0]) ,int(top_l[1]) , int(bottom_r[0]) ,int(bottom_r[1])] )\n",
    "    # x, y, w, h = [int(top_l[0]) ,int(top_l[1]) , int(bottom_r[0]) ,int(bottom_r[1])]\n",
    "    bboxes.append(box)\n",
    "    pred_text.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(image)\n",
    "# show_mask(masks[0], plt.gca())\n",
    "for input_box in bboxes : \n",
    "    show_box(input_box, plt.gca())\n",
    "\n",
    "\n",
    "plt.axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (bbox, text, prob) in result:\n",
    "    print(f\"Text: {text}\\nProbability: {prob:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def background_to_black ( image, index ):\n",
    "    # Apply the mask to the image\n",
    "    masked_img = image.copy()\n",
    "    masked_pixels = masked_img[masks[index]['segmentation']==True]\n",
    "    masked_img[masks[index]['segmentation']==False] = (0, 0, 0)  # Set masked pixels to black\n",
    "    return masked_img ,masked_pixels\n",
    "\n",
    "def get_sorted_by_coordinates(image, anns):\n",
    "    area_list=[]\n",
    "    cropped_image_dic ={}\n",
    "    mask_number = [] \n",
    "    mask_pixles_dic = {}\n",
    "    X_coord_list , Y_coord_list = [] , [] \n",
    "    for i in range(len(anns)):\n",
    "        x, y, width, height = anns[i]['bbox']\n",
    "        area = anns[i][\"area\"]\n",
    "        image_b, masked_pixels = background_to_black(image=image, index=i)\n",
    "        cropped_image = image_b[int(y):int(y+height), int(x):int(x+width)]\n",
    "        x_coord, y_coord = anns[i]['point_coords'][0]\n",
    "        X_coord_list.append(x_coord) \n",
    "        Y_coord_list.append(y_coord)\n",
    "\n",
    "\n",
    "        area_list.append(area)\n",
    "        cropped_image_dic[i] = cropped_image\n",
    "        mask_pixles_dic[i] = masked_pixels\n",
    "        mask_number.append(i)\n",
    "    df = pd.DataFrame([area_list,mask_number,X_coord_list,Y_coord_list])\n",
    "    df = df.T\n",
    "    df.columns = ['area','mask_number','X_corrd','Y_coord']\n",
    "    df.sort_values(by=['Y_coord','X_corrd'], ascending=True, inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    # cropped_image_dic has the same order of the masks number\n",
    "    return df , cropped_image_dic , mask_pixles_dic\n",
    "\n",
    "def process_images_and_sort_by_coordinates(image, masks):\n",
    "    image_dataframe, cropped_image_list , mask_pixels_dict = get_sorted_by_coordinates( image=image , anns=masks )\n",
    "    mask_number_list = image_dataframe['mask_number'].to_list()\n",
    "    list_of_images = [ cropped_image_list [idx ] for idx in mask_number_list  ]\n",
    "    print (image_dataframe.columns)\n",
    "    # print the first 5 rows of the dataframe\n",
    "    print (image_dataframe.head(n=10))\n",
    "\n",
    "    titles = [  ] \n",
    "    for idx in image_dataframe.index.to_list() :\n",
    "        titles.append(f\"index_{idx}\")\n",
    "    return list_of_images , titles , image_dataframe\n",
    "\n",
    "def experiment_grid(model_type, image):\n",
    "    mask_generator = load_sam_model(model_type=model_type)\n",
    "    masks = mask_generator.generate(image=image)\n",
    "    list_of_images , titles , image_dataframe = process_images_and_sort_by_coordinates(image = image, masks= masks)\n",
    "    show_images_grid( images=list_of_images , titles=titles )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_generator = load_sam_model(model_type=\"vit_b\")\n",
    "masks = mask_generator.generate(image=image)\n",
    "list_of_images , titles , image_dataframe = process_images_and_sort_by_coordinates(image = image, masks= masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(image)\n",
    "# input_box = np.array([5130., 4626.,  503.,  474.])\n",
    "# show_box(input_box, plt.gca())\n",
    "for input_box in bboxes : \n",
    "    show_box(input_box, plt.gca())\n",
    "# for ann in masks[0]['bbox']:\n",
    "for i in range(len(masks)):\n",
    "    x, y, width, height = masks[i]['bbox']\n",
    "    # this is the box definition\n",
    "    box = np.array([x, y, x+width, y+height])\n",
    "    show_box(box, plt.gca(), color='red')\n",
    "\n",
    "for idx, row in image_dataframe.iterrows():\n",
    "    x_coord = row['X_corrd']\n",
    "    y_coord = row['Y_coord']\n",
    "    title = titles[idx]\n",
    "    plt.text(x_coord, y_coord, title, color='white', fontsize=12, bbox=dict(facecolor='black', alpha=0.5))\n",
    "\n",
    "plt.axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(image)\n",
    "\n",
    "for idx, input_box in enumerate(bboxes) : \n",
    "    show_box(input_box, plt.gca())\n",
    "    # for each input box, the predicted text \n",
    "    # is written on the image\n",
    "    x, y,w,h = input_box\n",
    "    plt.text(x, y, pred_text[idx], color='white', fontsize=12, bbox=dict(facecolor='black', alpha=0.5))\n",
    "    plt.text(w, h, f\"box-{idx}\"  , color='white', fontsize=12, bbox=dict(facecolor='black', alpha=0.5))\n",
    "\n",
    "# for ann in masks[0]['bbox']:\n",
    "for i in range(len(masks)):\n",
    "    x, y, width, height = masks[i]['bbox']\n",
    "    # this is the box definition\n",
    "    box = np.array([x, y, x+width, y+height])\n",
    "    show_box(box, plt.gca(), color='red')\n",
    "\n",
    "\n",
    "\n",
    "plt.axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
